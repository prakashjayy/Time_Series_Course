{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1> Model Based Approaches </h1> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Model-Driven Methods</h4>\n",
    "- Predictor variables can also be used in time series forecasting. For example, suppose we wish to forecast the hourly electricity demand (ED) of a hot region during the summer period. A model with predictor variables might be of the form. \n",
    "- We call this an “explanatory model” because it helps explain what causes the variation in electricity demand.\n",
    "<p style=\"text-align: center;\"><b>$ED = f(current temperature, strength of economy, population, time of day, day of week, error)$ </b></p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models we can use in Time-Series \n",
    "All the machine learning models can be applied to time-series provided proper feature engineering. Some of the machine learning models used \n",
    "- Linear Regression\n",
    "- Decision Trees \n",
    "- Random Forests \n",
    "- GBM and Xgboost \n",
    "- Neural Networks \n",
    "\n",
    "We will explicitly donot model these here in this session, but will see what kind of Feature Engineering can be done. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions \n",
    "1) we assume that the model is a reasonable approximation to reality.  \n",
    "\n",
    "2) we make the following assumptions about the errors (ε_{1},…,ε_{T))\n",
    " - they have mean zero; otherwise the forecasts will be systematically biased.\n",
    " - they are not autocorrelated; otherwise the forecasts will be inefficient as there is more information to be exploited in the data.\n",
    " - they are unrelated to the predictor variables; otherwise there would be more information that should be included in the systematic part of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering \n",
    "\n",
    "In the case of the Australian  antibiotics Drug Sales dataset we have used, We have don't have any external variables like strength of the economy, health index of the country etc. So some of the basic things to consider while creating features for time-series modelling are \n",
    "\n",
    "- If the explantory variable is available for the future datapoints. We can sometimes use their forecasts and use it in our models, but this will increase our error rate. \n",
    "\n",
    "Lets look at some of the features we can create using the available date feature.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trend\n",
    "\n",
    "It is very common for time series data to be trending. A linear trend can be modelled by simply using $x_{1,t}=t$ as a predictor,\n",
    "\n",
    "\\begin{align*}\n",
    "y_{t} = \\beta_{0}+ \\beta_{1}*t+\\epsilon_{t}\n",
    "\\end{align*}\n",
    "\n",
    "where  t=1,…,T\n",
    "\n",
    "Trend can be easily used in Linear models. But cannot be used in  non-linear models like Decision Trees because\n",
    "\n",
    "![Decision Tree Drawbacks](Images/decision_tree.png)\n",
    "\n",
    "\n",
    "- The linear model approximates the data with a line, as we knew it would. This line provides quite a good forecast for the test data (the years after 2000), while glossing over some of the finer variations in both the training and the test data. \n",
    "- In The tree model, once we leave the data range for which the model has data, the model simply keeps predicting the last known point. The tree has no ability to generate “new” responses, outside of what was seen in the training data. This shortcoming applies to all models based on trees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Dummy Variables\n",
    "In a time-series data this can be any of the following: \n",
    "\n",
    "<h3> weekly </h3> \n",
    "- If you are dealing with daily data and see variations at daily level. using dummy variables makes sense. \n",
    "- This can be validated using box-plots\n",
    "- Sometimes you see variations across weekends and weekdays. create dummy variables only according to that.\n",
    "\n",
    "Example:  \n",
    "--------\n",
    "Electricity demand generally spikes during weekends compared to weekdays. \n",
    "\n",
    "<h3> Monthly </h3>\n",
    "- Aggregate the data to monthly and see if there is any variation in the month wise. Create a dummy feature if it makes sense to create one.\n",
    "- This can be validates using box-plots and line-plots as we have observed previosuly in session-2.\n",
    "\n",
    "Example:  \n",
    "--------\n",
    "Sales of Fasion retail stores peaks during December because of christmas and is normal during the rest of the year.\n",
    "\n",
    "<h3> Quarterly & Yearly </h3>\n",
    "- If there is variation in the data at Quarterly or year level. Use Quarterly features. \n",
    "- This can again be validated using box-plots and line-plots. \n",
    "\n",
    "Example:\n",
    "--------\n",
    "1) Ice-cream sales peaks during summer and is normal through-out the entire year.  \n",
    "2) Electricity demand Peaks during summer because of excessive use of AC's.\n",
    "\n",
    "<h3> Hourly </h3>\n",
    "- Useful for Companies which deal with hourly data. Uber for example, should consider hour as a feature as demand peaks during the early day hours (8am - 11am) and evening (5pm - 9pm). \n",
    "- Sometimes it is good to club hours and make features like peak hours vs non-peak hours. This will reduce the dimensionality and remove redundant variables.\n",
    "\n",
    "Caution:\n",
    "-------- \n",
    "While using Regression models, Many beginners will try to add a seventh dummy variable for the seventh category. This is known as the “dummy variable trap” because it will cause the regression to fail. There will be one too many parameters to estimate when an intercept is also included. The general rule is to use one fewer dummy variables than categories. So for quarterly data, use three dummy variables; for monthly data, use 11 dummy variables; and for daily data, use six dummy variables, and so on.\n",
    "\n",
    "This is not a problem with Decision Tree, as it only takes a variable if it explains the variation in the data. But do check for Over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Series \n",
    "An alternative to using seasonal dummy variables, especially for long seasonal periods, is to use Fourier terms. Jean-Baptiste Fourier was a French mathematician, born in the 1700s, who showed that a series of sine and cosine terms of the right frequencies can approximate any periodic function. We can use them for seasonal patterns.\n",
    "\n",
    "If  m is the seasonal period, then the first few Fourier terms are given by\n",
    "\n",
    "\\begin{align*}\n",
    "x_{1,t}=\\sin⁡(2*\\pi*t/m), x_{2,t}=\\cos⁡(2*\\pi*t/m), x_{3,t}=\\sin⁡(3*\\pi*t/m), x_{4,t}=cos⁡(4*\\pi*t/m), x_{5,t}=\\sin⁡(5*\\pi*t/m), x_{6,t}=cos⁡(6*\\pi*t/m), ...\n",
    "\\end{align*}\n",
    "\n",
    "and so on. \n",
    "\n",
    "If we have monthly seasonality, and we use the first 11 of these predictor variables, then we will get exactly the same forecasts as using 11 dummy variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holiday Effects:\n",
    "- Holidays have a large effect on your time-series forecasts. Most of the retail sales spike during the holidays and it is useful to keep them in your predictor variables.\n",
    "\n",
    "There are two different kind of holidays:\n",
    "- Occuring on the same day every year. For example, Christmas\n",
    "- Some festivals are not held on the same date each year, as they follow a different calender or system.\n",
    "  - Hindus follow their own calender (lunar calender). The dates are decided according to the moon's appearance. Diwali is celebrated on Karthik amawasya (Karthik being one of the months and amawasya being new moon) every year.\n",
    "  - Easter is celebrated on first Sunday after the first full moon following the first day of spring and the effect can last for several days. In this case, a dummy variable can be used with value one where the holiday falls in the particular time period and zero otherwise. with monthly data, when Easter falls in March then the dummy variable takes value 1 in March, when it falls in April, the dummy variable takes value 1 in April, and when it starts in March and finishes in April, the dummy variable is split proportionally between months.\n",
    "  \n",
    "So carefully check for holiday effects and model accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lag Variables:\n",
    "If there is Auto-Correlation in data, We can use lag as one of the variable in the time-series data. but be careful as while forecasting you need to use the last predicted values as the lag variable to the model and this propogates the error when you look more into the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tsFresh. \n",
    "- https://arxiv.org/abs/1610.07717\n",
    "- Automatic extraction of 100's of features, Those features describe basic characteristics of the time series such as the number of peaks, the average or maximal value or more complex features such as the time reversal symmetry statistic.\n",
    "- this package has a built-in filtering procedure. This filtering procedure evaluates the explaining power and importance of each characteristic for the regression or classification tasks at hand.\n",
    "- Github Link: https://github.com/blue-yonder/tsfresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet\n",
    "- Prophet is open source software released by Facebook's Core Data Science team. It has both python and R API.\n",
    "- It is a tool for producing high quality forecasts for time series data that has multiple seasonality with linear or non-linear growth. It is based on an additive model where non-linear trends are fit with yearly and weekly seasonality, plus holidays. It works best with daily periodicity data with at least one year of historical data. Prophet is robust to missing data, shifts in the trend, and large outliers.\n",
    "\n",
    "- Website: https://facebook.github.io/prophet/\n",
    "- GitHub: https://github.com/facebook/prophet\n",
    "- Paper: https://peerj.com/preprints/3190.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1> Thank you </h1> </center>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tondulkR]",
   "language": "python",
   "name": "Python [tondulkR]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
